\documentclass[11pt,a4paper,oneside]{report}

\input{include/packages}

\newcommand{\vikszerzoVezeteknev}{Fintha}
\newcommand{\vikszerzoKeresztnev}{Dénes Flórián}

\newcommand{\vikkonzulensAMegszolitas}{Dr.~}
\newcommand{\vikkonzulensAVezeteknev}{Bergmann}
\newcommand{\vikkonzulensAKeresztnev}{Gábor}

\newcommand{\vikkonzulensBMegszolitas}{}
\newcommand{\vikkonzulensBVezeteknev}{}
\newcommand{\vikkonzulensBKeresztnev}{}

\newcommand{\vikkonzulensCMegszolitas}{}
\newcommand{\vikkonzulensCVezeteknev}{}
\newcommand{\vikkonzulensCKeresztnev}{}

\newcommand{\vikcim}{Performance analysis of a language tooling}
\newcommand{\viktanszek}{\bmemit}
\newcommand{\vikdoktipus}{\bsc}
\newcommand{\vikmunkatipusat}{szakdolgozatot}

\input{include/tdk-variables}
\newcommand{\szerzoMeta}{\vikszerzoVezeteknev{} \vikszerzoKeresztnev}
\input{include/thesis-en}
\input{include/preamble}

\begin{document}

\pagenumbering{gobble}
\selectthesislanguage
\include{include/titlepage}
\tableofcontents\cleardoublepage
\include{include/declaration}

% --- ABSTRACT --------------------------------------------------------------- %

\pagenumbering{roman}
\setcounter{page}{1}

\selecthungarian
\chapter*{Kivonat}\addcontentsline{toc}{chapter}{Kivonat}
A szakdolgozat egy modellek validációjával foglalkozó eszköz teljesítményével
kapcsolatos problémáinak nyomozásáról és orvoslásáról szól.

A modellek validációja önmagában egy erőforrásigényes feladat, így nem
meglepő, hogy egy ilyen eszközben találunk javítani valót a teljesítmény terén.
A vizsgált eszköz a VIATRA Query, melyben mintákat definiálhatunk, és
illeszthetünk modellekre az esetleges hibák felderítésére, egy kifejezetten erre
szolgáló nyelv segítségével (VIATRA Query Language, VQL). A közelmúltban több
felhasználónak is feltűnt, hogy a VQL szerkesztő indokolatlanul lassan reagál
a lekérdezések szerkesztésére, mely megakadályozza a gördülékeny munkamenetet.

A dolgozatban nagy vonalakban ismertetem a VIATRA Query-t, mint szoftvert,
valamint mutatok néhány egyszerű példát a használatára minták írásán keresztül.

A szoftver bemutatása után egy ismerten lassú példafájl használatával bemutatom
a probléma forrásának felderítését egy profilozó szoftver segítségével. Emellett
részletekbe menően ismertetem a releváns részek működését, valamint kidolgozok
egy potenciális javítást is.

Végül miután elkészült a javítás, utolsó lépésként bemutatom, hogyan lehet a
változtatásokat elküldeni a VIATRA fejlesztőinek, hogy a szoftver következő
kiadása már tartalmazhassa őket.
\vfill

\selectenglish
\chapter*{Abstract}\addcontentsline{toc}{chapter}{Abstract}
This thesis is about investigating and solving the performance issues of a tool,
which validates models.

Model validation by itself is a resource-intensive task. As such, it's not
surprising, that we can find things to improve in such a tool.
The tool we inspect is VIATRA Query, in which we can defined patterns, and match
them on models to check them for potential errors. This is done in a
domain-specific language (VIATRA Query Language, VQL). In the past, multiple
users have noticed, that the VQL editor reacts in an unreasonably slow manner to
changes in the VQL editor, which obstructs a smooth workflow.

In the thesis, I'll broadly show the VIATRA Query software, and show the
basic usage of it through some simple patterns.

After showing the tool itself, I'll present the investigation of the problem by
using a file, that is known to cause slowdowns, and a profiler software. Along
with this, I'll show the details about how that part of the software works, and
work out a potential fix for it, too.

Finally, after the my fix is in a working state, I'll show how to send changes
to the developers of VIATRA, so my fix could be included in its next release.
\vfill

% ---------------------------------------------------------------------------- %

\cleardoublepage
\selectthesislanguage
\newcounter{romanPage}
\setcounter{romanPage}{\value{page}}
\stepcounter{romanPage}
\pagenumbering{arabic}

% --- CONTENT ---------------------------------------------------------------- %

\chapter{Introduction}
\section{Introduction to VIATRA Query}
\subsection{The VIATRA plugins}
VIATRA (VIsual Automated model TRAnsformations) is an open-source project backed
by the Eclipse Foundation, which integrates into the Eclipse development
environment, providing functionalities like obfuscation, transformation, and
query of models.

In my thesis, I worked with the VIATRA Query component, which is a tool for
writing and executing queries on models.

During the thesis I won't install VIATRA as an Eclipse package, but build parts
of it (the query engine) from source, so I can debug and modify its code, and
omit additional functionality, that I won't need.

\begin{figure}[ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/eclipse-viatra.png}
\caption{The VIATRA Transformation Development perspective in Eclipse}
\label{fig:eclipse-viatra}
\end{figure}

\subsection{VIATRA Query Language (VQL)}
In VIATRA Query, we can write patterns that are matched on a loaded model. This
is done through a powerful domain-specific language (DSL) called the VIATRA
Query Language (VQL). The VIATRA Query plugins provide an editor with proper
syntax highlighting to make writing patterns easier.

Pattern syntax resembles Prolog in a way, that instead of writing functions, we
write statements, which are evaluated. The engine will try to calculate each
matching dataset for the pattern.

\begin{lstlisting}[frame=single]
pattern grandparentOf(grandchild : Person, grandparent : Person) {
    Person.parent(grandchild, parent);
    Person.parent(parent, grandparent);
}
\end{lstlisting}

In this pattern, we declare a grandparent of a person, as a parent of one of its
parents. This will match each grandparent-grandchild relation.

Patterns can have multiple declarations, and use other patterns.
If we separately track mothers and fathers instead of just parents, our patterns
may look like this.

\begin{lstlisting}[frame=single]
pattern parentOf(child : Person, parent : Person) {
    Person.mother(child, parent);
} or {
    Person.father(child, parent);
}

pattern grandparentOf(grandchild : Person, grandparent : Person) {
    find parentOf(grandchild, parent);
    find parentOf(parent, grandparent);
}
\end{lstlisting}

The last language feature I'll talk about is aggregation. You can use
aggregators for numeric results like \textbf{count}, \textbf{max}, \textbf{min},
and \textbf{sum}. In this snippet, the underscore means a parameter that is not
used in our pattern.

\begin{lstlisting}[frame=single]
pattern grandparentAmount(child : Person, amount) {
    amount == count find grandparentOf(child, _);
}
\end{lstlisting}

\subsection{Formulating constraints}
One can also provide model validation, by writing \textbf{constraint patterns}.
This raises an error if VIATRA finds any matches to that pattern. This can be
done by annotating our validation pattern.

\begin{lstlisting}[frame=single]
@Constraint(targetEditorId = "org.dfintha.familytree",
            severity = "error",
            message = "Person is both a parent and grandparent of someone.",
            key = {"parent"})
pattern bothParentAndGrandparent(person : Person, parent : Person) {
    find parentOf(person, parent);
    find grandparentOf(person, parent);
}
\end{lstlisting}

\section{Work environment}
\subsection{Eclipse Platform for VIATRA development}
VIATRA, as an Eclipse plugin is developed in Eclipse itself. As such, I needed
an Eclipse environment to develop it. Normally, this should be a straightforward
process, utilizing the Eclipse Oomph installer, but at the time I did my
research the installer didn't work as expected, so I had to install the required
plugins, and add the VIATRA source code to my environment manually.

The detailed steps on how to do this is is written down on the VIATRA project
website.

\subsection{YourKit Java Profiler}
Since the main issue we have to investigate is a slowdown, I had to use a
profiler software.

Profiler software examine various aspects of software execution, like how much
time did we spend in a function, or how many times a function was called, and
compile the measured data into snapshots, where the developer can analyze the
results.

During my thesis, I used the YourKit Java Profiler, for which the faculty
already owns a license.

After installing the profiler, I also had to install its Eclipse plugin, so I
could configure the profiler and start profiling of the software in Eclipse.

\begin{figure}[ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/yourkit-profiler.png}
\caption{YourKit Java Profiler in action}
\label{fig:yourkit-profiler}
\end{figure}

\chapter{Finding the cause of the editor slowdown}
\section{Problem description}
Users have complained, that the editor severely slows down during VQL pattern
editing, while working larger or more complex queries. To prove this statement,
I had to get a query that is both known to be slow and is correct. Fortunately,
there is an open-source VIATRA project, which contains a file, which causes
severe slowdowns, although, this generated file was not correct.

To create a test environment, I took that file, and fixed it in a new query
project, providing myself a clean slate for testing. The resulting file was over
5000 lines long and had a numerous amount of patterns referencing each other.
Editing this file caused 5-6 second hangups even with a moderately strong
computer.

\section{Profiling the query language editor}
\subsection{The profiling workflow}
First of all, I had to create a profiling workflow, which describes the steps
taken to profile the software. Following a fixed workflow ensures that snapshots
will not contain unrelated parts of the software execution, and that snapshots
will represent the same steps taken.

\begin{enumerate}
    \item{Start VIATRA in profiling mode, but without starting profiling itself.}
    \item{Wait for Eclipse to start and finish initial tasks.}
    \item{Open the query file, and wait for it to completely load, and highlight syntax.}
    \item{Navigate to a pattern, which we will manually duplicate.}
    \item{\textbf{Start profiling in the profiler software.}}
    \item{Manually type in the pattern again, with a different name.}
    \item{\textbf{Stop profiling in the profiler software, and save a snapshot.}}
    \item{Discard the changes we made in the file.}
    \item{Quit Eclipse.}
\end{enumerate}

\subsection{Profiling with default settings}
Having a sound profiling plan, I started profiling the software. During my
first profiling session, I did notice the hangups, when I edited the query. This
session provided me with the following suspicious function trail. Each row of
one or more functions in this table was called by the one before it. Rows with
bold font are representing functions inside the VIATRA code base.

We spent most of the time in the
\texttt{XtextDocumentReconcileStrategy.postParse} function. The table below
gives detailed information about which functions called by \texttt{postParse}
were the most costly.

\begin{table}[ht]
    \footnotesize
    \centering
    \begin{tabular}{ l c }
        \toprule
        Function & Time (\%) \\
        \midrule
        XtextDocumentReconcileStrategy.postParse & 100\% \\
        EcoreUtil2.resolveLazyCrossReferences & 99\% \\
        BatchLinkableResource.resolveLazyCrossReferences & 99\% \\
        BatchLinkingService.resolveBatched & 97\% \\
        AbstractBatchTypeResolver.resolveTypes & 97\% \\
        CachingBatchTypeResolver.doResolveTypes & 97\% \\
        OnChangeEvictingCache.get & 95\% \\
        CachingBatchTypeResolver\$1.get & 95\% \\
        CachingBatchTypeResolver\$1.get & 95\% \\
        DefaultBatchTypeResolver.getTypeResolver & 95\% \\
        LogicalContainerAwareBatchTypeResolver.getEntryPoints & 92\% \\
        BatchLinkableResource.getContents & 92\% \\
        DerivedStateAwareResource.installDerivedState & 92\% \\
        \textbf{EMFPatternJvmModelAssociator.installDerivedState} & 92\% \\
        JvmModelAssociator.installDerivedState & 92\% \\
        JvmModelAssociator\$1.run & 91\% \\
        \textbf{EMFPatternLanguageJvmModelInferrer lambdas} & 78\% \\
        \bottomrule
    \end{tabular}
    \caption{Merged callee run times in postParse with default settings}
    \label{tab:postparse-default}
\end{table}

The EMFPatternLanguageJvmModelInferrer class has multiple lambdas, but the top
three with most time spent in them are all calling the
\texttt{AbstractTypeInferrer.getJvmType} method, which is responsible for their
long run time.

\subsection{Profiling without automatic update of target platform metamodels}
After turning off this automatic update feature, we can have more concise
profiling results. Repeating the same process yielded the following, similar
results. Now the \texttt{XtextDocumentReconcileStrategy.postParse} function only
took 67\% of the total run time.

\begin{table}[ht]
    \footnotesize
    \centering
    \begin{tabular}{ l c }
        \toprule
        Function & Time (\%) \\
        \midrule
        XtextDocumentReconcileStrategy.postParse & 100\% \\
        EcoreUtil2.resolveLazyCrossReferences & 96\% \\
        BatchLinkableResource.resolveLazyCrossReferences & 96\% \\
        BatchLinkingService.resolveBatched & 87\% \\
        AbstractBatchTypeResolver.resolveTypes & 87\% \\
        CachingBatchTypeResolver.doResolveTypes & 87\% \\
        OnChangeEvictingCache.get & 75\% \\
        CachingBatchTypeResolver\$1.get & 75\% \\
        CachingBatchTypeResolver\$1.get & 75\% \\
        DefaultBatchTypeResolver.getTypeResolver & 75\% \\
        LogicalContainerAwareBatchTypeResolver.getEntryPoints & 62\% \\
        BatchLinkableResource.getContents & 62\% \\
        DerivedStateAwareResource.installDerivedState & 62\% \\
        \textbf{EMFPatternJvmModelAssociator.installDerivedState} & 62\% \\
        JvmModelAssociator.installDerivedState & 61\% \\
        JvmModelAssociator\$1.run & 57\% \\
        \textbf{EMFPatternLanguageJvmModelInferrer lambdas} & 52\% \\
        \bottomrule
    \end{tabular}
    \caption{Merged callee run times in postParse without automatic update}
    \label{tab:postparse-no-auto-update}
\end{table}

\section{Conclusion}
In conclusion, metamodel updates are very costly, and even though turning
automatic updates off does save some time, these updates still happen
frequently, and should be optimized. My next step was to understand the code
responsible for type inference, and look for opportunities to optimize it.

My choice of optimization is implementing a cache for the
\texttt{AbstractTypeInferrer}, to avoid repeated inferences of the same type.
Since it takes a large part of the run time (33\% without automatic update,
and 75\% with it), the speedup should be significant.

\chapter{Optimizing query metamodel generation}
\section{The Xtext language framework}
The VIATRA Query Language was written using the Xtext language framework, which
is an effective tool for writing programming and domain-based languages. This
framework provides a proper environment to work with our language in Eclipse,
including syntax highlighting.

To validate our query, the Xtext framework parses the query written in VQL
(partially utilizing VIATRA's code), creates a document object model (DOM) of
it, and finally, runs checks on said model. The process of building this DOM is
calling the \texttt{IDerivedStateComputer.installDerivedState} function in the
Xtext framework, which is responsible for producing the current state of our
query.

\begin{figure}[ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/xtext-validation-process.png}
\caption{The Xtext validation process}
\label{fig:xtext-validation-process}
\end{figure}

The slowest part of this process is building the DOM from the parsed query code.
During model building, the types of variables must be interpreted, and while
most of these variables have a \textbf{declared type}, some of them do not, and
VIATRA Query has to \textbf{infer their types} based on the context they reside
in.

\section{Implementing a type inferrer cache}
\subsection{Inspecting the original functionality}
During the type inference process, \texttt{getJvmType} is called numerous times,
resulting in a massive amount of processing time spent there. Let us see, how
this function works.

\begin{lstlisting}[language=java]
// ...

/**
 * @since 1.3
 */
@Override
public IInputKey getType(Expression ex) {
    final IInputKey declaredType = getDeclaredType(ex);
    if (declaredType != null) {
        return declaredType;
    } else {
        return getInferredType(ex);
    }
}

//...

/**
 * @since 1.3
 */
@Override
public JvmTypeReference getJvmType(Expression ex, EObject context) {
    return typeSystem.toJvmTypeReference(getType(ex), context);
}

// ...
\end{lstlisting}

The profiling session showed us that we spend most of the time in the
\texttt{getType} function, and inside that, the \texttt{getInferredType}
function, which actually does a costly type calculation, and does so repeatedly.
This looks like a good candidate for some caching mechanism.

\subsection{Caching computed results}
My first approach was adding a cache to the \texttt{AbstractTypeInferrer} class,
storing the types (\texttt{IInputKey}) of \texttt{Expression} objects. I thought
this cache would be invalidated at the start of each validation process. As
such.

The following changes were made to the \texttt{AbstractTypeInferrer} class.

\begin{lstlisting}[language=java]
// ...

private HashMap<Expression, IInputKey> typeCache;

// ...

/**
 * @since 1.3
 */
@Override
public IInputKey getType(Expression ex) {
    if (typeCache == null)
        typeCache = new HashMap<>();

    if (!typeCache.containsKey(ex)) {
        final IInputKey declaredType = getDeclaredType(ex);
        if (declaredType != null) {
            typeCache.put(ex,  declaredType);
        } else {
            typeCache.put(ex, getInferredType(ex));
        }
    }
    return typeCache.get(ex);
}

// ...
\end{lstlisting}

\subsection{Clearing the cache}
Along with the caching, I also had to perform cache invalidation at the
beginning of each validation process. To do so, I've added a function to clear
the cache in \texttt{AbstractTypeInferrer}, which is called at the start of the
\texttt{installDerivedState} function.

\begin{lstlisting}[language=java]
// ...

/**
 * @since 2.5
 */
public void clearCache() {
    typeCache = new HashMap<>();
}

// ...
\end{lstlisting}

\begin{lstlisting}[language=java]
// ...

@Override
public void installDerivedState(DerivedStateAwareResource resource, boolean preIndexingPhase) {
    feedback.clearMarkers(resource, IErrorFeedback.JVMINFERENCE_ERROR_TYPE);
    if (typeInferrer instanceof AbstractTypeInferrer)
        ((AbstractTypeInferrer) typeInferrer).clearCache();

    calculateDerivedVariableObjects(resource);
    super.installDerivedState(resource, preIndexingPhase);
    if (!preIndexingPhase) {
        calculateAggregateTypes(resource);
    }
}

// ...
\end{lstlisting}

\subsection{Comparing the optimized state with the original one}
After making these changes, I did another profiling session, with the same
workflow described above. Seemingly my first solution did not fully accomplish
my goal, the run time of the validation process remained close to the same. The
\texttt{XtextDocumentReconcileStrategy.postParse} function still ate up 64\% of
the runtime (compared to the original 67\%), but the type inference code became
slightly faster.

Below is a table with comparison between the original source code (with
automatic updates turned off) and my solution.

\begin{table}[ht]
    \footnotesize
    \centering
    \begin{tabular}{ l c c }
        \toprule
        Function & Time (\%), Original & Time (\%), Changed \\
        \midrule
        XtextDocumentReconcileStrategy.postParse & 100\% & 100\% \\
        EcoreUtil2.resolveLazyCrossReferences & 99\% & 95\% \\
        BatchLinkableResource.resolveLazyCrossReferences & 99\% & 95\% \\
        BatchLinkingService.resolveBatched & 97\% & 84\% \\
        AbstractBatchTypeResolver.resolveTypes & 97\% & 84\% \\
        CachingBatchTypeResolver.doResolveTypes & 97\% & 84\% \\
        OnChangeEvictingCache.get & 95\% & 70\% \\
        CachingBatchTypeResolver\$1.get & 95\% & 70\% \\
        CachingBatchTypeResolver\$1.get & 95\% & 70\% \\
        DefaultBatchTypeResolver.getTypeResolver & 95\% & 70\% \\
        LogicalContainerAwareBatchTypeResolver.getEntryPoints & 92\% & 58\% \\
        BatchLinkableResource.getContents & 92\% & 58\% \\
        DerivedStateAwareResource.installDerivedState & 92\% & 58\% \\
        \textbf{EMFPatternJvmModelAssociator.installDerivedState} & 92\% & 58\% \\
        JvmModelAssociator.installDerivedState & 92\% & 57\% \\
        JvmModelAssociator\$1.run & 91\% & 54\% \\
        \textbf{EMFPatternLanguageJvmModelInferrer lambdas} & 52\% & 48\% \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of run time with the unmodified code and my first solution}
    \label{tab:first-solution-comparison}
\end{table}

The suspicious part was the ratio of the time spent in functions called by the
\texttt{getType} function. The purpose of my cache was minimizing calls to the
\texttt{getInferredType} function, which took the most time. However, the amount
of time spent in the \texttt{getInferredType} function was roughly the same (
77\% and 76\%, respectively).

My first suspicion was that \texttt{Expression} objects are never the "same",
so two \texttt{Expression}s with the same content evalute to two different
hashes, and my cache always misses.

To make sure, I did another profiling, now in trace mode. Trace mode means
counting function calls along with time spent with them, which may seem like the
best way to profile software, but this mode comes with a major slowdown, making
it harder to perform the profiling workflow.

The results of trace mode profiling have proven my suspicion false. The
\texttt{getType} function itself was called \textbf{13346 times}, however its
callees had smaller call counts. Below is the callee list of with call counts
included.

\begin{table}[ht]
    \footnotesize
    \centering
    \begin{tabular}{ l c c }
        \toprule
        Function & Time (\%)& Count \\
        \midrule
        EMFTypeInferrer.getInferredType & 97\% & 121 \\
        EMFTypeInferrer.getDeclaredType & 3\% & 2245 \\
        \bottomrule
    \end{tabular}
    \caption{Time and call count of callees of \texttt{getType} with my first solution}
    \label{tab:first-solution-call-counts}
\end{table}

\subsection{Conclusion}
If we look at the previous implementation of \texttt{getType},
\texttt{getDeclaredType} was always called the same amount of times as
\texttt{getType} itself, and if it failed,\texttt{getInferredType} was also
called. With my first solution, the call count of the two functions added
together (2366) was only 17.7\% of the total call count. This means that 82.3\%
of times the cache did not miss.

Even though this change did not cause the significant speedup I've expected,
it still is a useful addition to the project. As such, I've decided to keep
these changes, but continue my investigation.

\chapter{Applying changes to the main code repository}
\section{Documenting my changes}
It is just natural, that we would document the changes we've made to the users,
even if it's not a functional change. The VIATRA documentation is written in
asciidoc format, and each release has its own changelog.

\section{Opening a bug tracker ticket}
The Eclipse Foundation uses Bugzilla as its bug tracker. Each known bug has a
ticket assigned, and this ticket has a unique identifier. Tickets contain
a detailed description of the issue, and some other metadata, such as product,
version, importance, and target milestone.

For this thesis work, a new Bugzilla ticket was introduced:
Bug 569178 -- Improve language tooling performance.

\begin{figure}[ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/bugzilla.png}
\caption{Eclipse Foundation's Bugzilla bug tracker}
\label{fig:bugzilla}
\end{figure}

These tickets can be assigned to developers, and have their status tracked, so
the overseeing the flow of work would be trivial.

\section{Keeping the changes in version control}
VIATRA source code is stored in a Git repository, hosted by the Eclipse
foundation. To obtain the source code, developers have to \textbf{clone} the
repository, and work can be done on their own \textbf{branches}. Git has a
command-line tool, but Eclipse can also manage version control by using the
Git perspective.

\begin{figure}[ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/eclipse-git.png}
\caption{The Git perspective in Eclipse}
\label{fig:eclipse-git}
\end{figure}

Changes on the source code are contained in \textbf{commits}, and in Eclipse
development each bug fixing commit correlates with a Bugzilla ticket, and
should include the bug identifier and title in its commit message, along with
a short description, sign-off information that proves the changes in the commit
were made by me, and a change ID for the code review tool.

\begin{lstlisting}
[569178] Improve language tooling performance

This commit introduces a caching mechanism for the AbstractTypeInferrer
class, allowing it to cache inferred types and avoiding repeatedly
calculating the types of equal expression.

Change-Id: I0000000000000000000000000000000000000000
Signed-off-by: Dénes Fintha <denes.fintha@gmail.com>
\end{lstlisting}

\section{Asking for code review}
Before any code could be integrated to the mainstream VIATRA source, peer review
must be conducted. The Eclipse Foundation uses Gerrit to do so, which is a
web-based code review tool.

Gerrit support multiple versions of the same commit, identified via a
\texttt{Change-Id}, which is denoted in the commit message.

In Gerrit, developers can see other developers' work, and comment and rate their
commits. The common practice is, that two other developers must accept a
commit before it can be integrated.

\begin{figure}[ht]
\centering
\includegraphics[width=150mm, keepaspectratio]{figures/gerrit.png}
\caption{The Gerrit Code Review tool}
\label{fig:gerrit}
\end{figure}

% ---------------------------------------------------------------------------- %

\listoffigures\addcontentsline{toc}{chapter}{\listfigurename}
\listoftables\addcontentsline{toc}{chapter}{\listtablename}

\addcontentsline{toc}{chapter}{\bibname}
\nocite{*} % FIXME remove
\bibliography{bib/mybib}

\label{page:last}
\end{document}
